{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart Disease Prediction using Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\welcome\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\welcome\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\welcome\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\welcome\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\welcome\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\welcome\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\welcome\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\welcome\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\welcome\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\welcome\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\welcome\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\welcome\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics \n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras import initializers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Users/welcome/Desktop/Heart Disease/dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>135</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>212</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>105</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>228</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>178</td>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   55    0   2       135   250    0        2      161      0      1.4      2   \n",
       "1   59    1   3       150   212    1        0      157      0      1.6      1   \n",
       "2   41    0   2       105   198    0        0      168      0      0.0      1   \n",
       "3   66    1   4       160   228    0        2      138      0      2.3      1   \n",
       "4   40    1   1       140   199    0        0      178      1      1.4      1   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     3       1  \n",
       "1   0     3       1  \n",
       "2   1     3       1  \n",
       "3   0     6       1  \n",
       "4   0     7       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"target\"]-=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>135</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>212</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>105</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>228</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>178</td>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   55    0   2       135   250    0        2      161      0      1.4      2   \n",
       "1   59    1   3       150   212    1        0      157      0      1.6      1   \n",
       "2   41    0   2       105   198    0        0      168      0      0.0      1   \n",
       "3   66    1   4       160   228    0        2      138      0      2.3      1   \n",
       "4   40    1   1       140   199    0        0      178      1      1.4      1   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     3       0  \n",
       "1   0     3       0  \n",
       "2   1     3       0  \n",
       "3   0     6       0  \n",
       "4   0     7       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final = pd.get_dummies(data, columns=['sex', 'cp' ,'fbs', 'restecg', 'exang', 'slope', 'ca'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>thalach</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "      <th>sex_0</th>\n",
       "      <th>sex_1</th>\n",
       "      <th>cp_1</th>\n",
       "      <th>...</th>\n",
       "      <th>restecg_2</th>\n",
       "      <th>exang_0</th>\n",
       "      <th>exang_1</th>\n",
       "      <th>slope_1</th>\n",
       "      <th>slope_2</th>\n",
       "      <th>slope_3</th>\n",
       "      <th>ca_0</th>\n",
       "      <th>ca_1</th>\n",
       "      <th>ca_2</th>\n",
       "      <th>ca_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55</td>\n",
       "      <td>135</td>\n",
       "      <td>250</td>\n",
       "      <td>161</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59</td>\n",
       "      <td>150</td>\n",
       "      <td>212</td>\n",
       "      <td>157</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>105</td>\n",
       "      <td>198</td>\n",
       "      <td>168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66</td>\n",
       "      <td>160</td>\n",
       "      <td>228</td>\n",
       "      <td>138</td>\n",
       "      <td>2.3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>140</td>\n",
       "      <td>199</td>\n",
       "      <td>178</td>\n",
       "      <td>1.4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  trestbps  chol  thalach  oldpeak  thal  target  sex_0  sex_1  cp_1  \\\n",
       "0   55       135   250      161      1.4     3       0      1      0     0   \n",
       "1   59       150   212      157      1.6     3       0      0      1     0   \n",
       "2   41       105   198      168      0.0     3       0      1      0     0   \n",
       "3   66       160   228      138      2.3     6       0      0      1     0   \n",
       "4   40       140   199      178      1.4     7       0      0      1     1   \n",
       "\n",
       "   ...  restecg_2  exang_0  exang_1  slope_1  slope_2  slope_3  ca_0  ca_1  \\\n",
       "0  ...          1        1        0        0        1        0     1     0   \n",
       "1  ...          0        1        0        1        0        0     1     0   \n",
       "2  ...          0        1        0        1        0        0     0     1   \n",
       "3  ...          1        1        0        1        0        0     1     0   \n",
       "4  ...          0        0        1        1        0        0     1     0   \n",
       "\n",
       "   ca_2  ca_3  \n",
       "0     0     0  \n",
       "1     0     0  \n",
       "2     0     0  \n",
       "3     0     0  \n",
       "4     0     0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_final.drop(['target'], axis=1).values\n",
    "y = data_final['target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.41691652,  1.66486104,  0.77327228, ..., -0.51102495,\n",
       "        -0.38879659,  3.85227206],\n",
       "       [ 1.08444628,  0.50700194,  1.73025776, ..., -0.51102495,\n",
       "        -0.38879659, -0.25958707],\n",
       "       [ 0.64115262,  1.08593149,  0.22642344, ..., -0.51102495,\n",
       "         2.572039  , -0.25958707],\n",
       "       ...,\n",
       "       [-0.35625809, -0.36139239, -0.65244078, ...,  1.95685163,\n",
       "        -0.38879659, -0.25958707],\n",
       "       [ 1.08444628,  2.82272014,  1.5349546 , ..., -0.51102495,\n",
       "        -0.38879659, -0.25958707],\n",
       "       [-2.24025611, -0.76664307, -1.25788057, ..., -0.51102495,\n",
       "        -0.38879659, -0.25958707]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\welcome\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\welcome\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 396 samples, validate on 171 samples\n",
      "Epoch 1/40\n",
      "396/396 [==============================] - 1s 4ms/step - loss: 0.6930 - accuracy: 0.5657 - val_loss: 0.6916 - val_accuracy: 0.7836\n",
      "Epoch 2/40\n",
      "396/396 [==============================] - 0s 930us/step - loss: 0.6565 - accuracy: 0.8434 - val_loss: 0.6036 - val_accuracy: 0.7485\n",
      "Epoch 3/40\n",
      "396/396 [==============================] - 0s 986us/step - loss: 0.5018 - accuracy: 0.8384 - val_loss: 0.5277 - val_accuracy: 0.8772\n",
      "Epoch 4/40\n",
      "396/396 [==============================] - 0s 910us/step - loss: 0.3948 - accuracy: 0.8788 - val_loss: 0.3789 - val_accuracy: 0.8947\n",
      "Epoch 5/40\n",
      "396/396 [==============================] - 0s 978us/step - loss: 0.3020 - accuracy: 0.8864 - val_loss: 0.3328 - val_accuracy: 0.8947\n",
      "Epoch 6/40\n",
      "396/396 [==============================] - 0s 1ms/step - loss: 0.2828 - accuracy: 0.8914 - val_loss: 0.3317 - val_accuracy: 0.8830\n",
      "Epoch 7/40\n",
      "396/396 [==============================] - 0s 869us/step - loss: 0.2694 - accuracy: 0.8939 - val_loss: 0.3181 - val_accuracy: 0.8947\n",
      "Epoch 8/40\n",
      "396/396 [==============================] - 0s 879us/step - loss: 0.2595 - accuracy: 0.9015 - val_loss: 0.3180 - val_accuracy: 0.9123\n",
      "Epoch 9/40\n",
      "396/396 [==============================] - 0s 788us/step - loss: 0.2517 - accuracy: 0.9066 - val_loss: 0.3089 - val_accuracy: 0.9181\n",
      "Epoch 10/40\n",
      "396/396 [==============================] - 0s 751us/step - loss: 0.2384 - accuracy: 0.9192 - val_loss: 0.2935 - val_accuracy: 0.9064\n",
      "Epoch 11/40\n",
      "396/396 [==============================] - 0s 687us/step - loss: 0.2289 - accuracy: 0.9242 - val_loss: 0.2956 - val_accuracy: 0.9064\n",
      "Epoch 12/40\n",
      "396/396 [==============================] - 0s 705us/step - loss: 0.2165 - accuracy: 0.9242 - val_loss: 0.2955 - val_accuracy: 0.9298\n",
      "Epoch 13/40\n",
      "396/396 [==============================] - 0s 639us/step - loss: 0.2105 - accuracy: 0.9167 - val_loss: 0.2892 - val_accuracy: 0.9064\n",
      "Epoch 14/40\n",
      "396/396 [==============================] - 0s 657us/step - loss: 0.2028 - accuracy: 0.9217 - val_loss: 0.2733 - val_accuracy: 0.9240\n",
      "Epoch 15/40\n",
      "396/396 [==============================] - 0s 584us/step - loss: 0.1926 - accuracy: 0.9268 - val_loss: 0.2728 - val_accuracy: 0.9181\n",
      "Epoch 16/40\n",
      "396/396 [==============================] - 0s 670us/step - loss: 0.1860 - accuracy: 0.9293 - val_loss: 0.2831 - val_accuracy: 0.9123\n",
      "Epoch 17/40\n",
      "396/396 [==============================] - 0s 606us/step - loss: 0.1786 - accuracy: 0.9318 - val_loss: 0.2744 - val_accuracy: 0.9298\n",
      "Epoch 18/40\n",
      "396/396 [==============================] - 0s 604us/step - loss: 0.1728 - accuracy: 0.9343 - val_loss: 0.2670 - val_accuracy: 0.9298\n",
      "Epoch 19/40\n",
      "396/396 [==============================] - 0s 571us/step - loss: 0.1581 - accuracy: 0.9394 - val_loss: 0.2851 - val_accuracy: 0.9240\n",
      "Epoch 20/40\n",
      "396/396 [==============================] - 0s 546us/step - loss: 0.1433 - accuracy: 0.9520 - val_loss: 0.2622 - val_accuracy: 0.9357\n",
      "Epoch 21/40\n",
      "396/396 [==============================] - 0s 558us/step - loss: 0.1328 - accuracy: 0.9545 - val_loss: 0.2716 - val_accuracy: 0.9357\n",
      "Epoch 22/40\n",
      "396/396 [==============================] - 0s 510us/step - loss: 0.1217 - accuracy: 0.9571 - val_loss: 0.2747 - val_accuracy: 0.9357\n",
      "Epoch 23/40\n",
      "396/396 [==============================] - 0s 571us/step - loss: 0.1113 - accuracy: 0.9646 - val_loss: 0.2972 - val_accuracy: 0.9357\n",
      "Epoch 24/40\n",
      "396/396 [==============================] - 0s 541us/step - loss: 0.1075 - accuracy: 0.9697 - val_loss: 0.2949 - val_accuracy: 0.9298\n",
      "Epoch 25/40\n",
      "396/396 [==============================] - 0s 452us/step - loss: 0.1016 - accuracy: 0.9722 - val_loss: 0.3017 - val_accuracy: 0.9123\n",
      "Epoch 26/40\n",
      "396/396 [==============================] - 0s 460us/step - loss: 0.0955 - accuracy: 0.9697 - val_loss: 0.2968 - val_accuracy: 0.9357\n",
      "Epoch 27/40\n",
      "396/396 [==============================] - 0s 450us/step - loss: 0.0804 - accuracy: 0.9747 - val_loss: 0.3319 - val_accuracy: 0.9181\n",
      "Epoch 28/40\n",
      "396/396 [==============================] - 0s 475us/step - loss: 0.0719 - accuracy: 0.9823 - val_loss: 0.3039 - val_accuracy: 0.9298\n",
      "Epoch 29/40\n",
      "396/396 [==============================] - 0s 447us/step - loss: 0.0629 - accuracy: 0.9874 - val_loss: 0.3293 - val_accuracy: 0.9298\n",
      "Epoch 30/40\n",
      "396/396 [==============================] - 0s 422us/step - loss: 0.0579 - accuracy: 0.9874 - val_loss: 0.3326 - val_accuracy: 0.9298\n",
      "Epoch 31/40\n",
      "396/396 [==============================] - 0s 425us/step - loss: 0.0507 - accuracy: 0.9874 - val_loss: 0.3369 - val_accuracy: 0.9298\n",
      "Epoch 32/40\n",
      "396/396 [==============================] - 0s 417us/step - loss: 0.0467 - accuracy: 0.9874 - val_loss: 0.3453 - val_accuracy: 0.9298\n",
      "Epoch 33/40\n",
      "396/396 [==============================] - 0s 417us/step - loss: 0.0443 - accuracy: 0.9874 - val_loss: 0.3518 - val_accuracy: 0.9181\n",
      "Epoch 34/40\n",
      "396/396 [==============================] - 0s 427us/step - loss: 0.0380 - accuracy: 0.9924 - val_loss: 0.3383 - val_accuracy: 0.9357\n",
      "Epoch 35/40\n",
      "396/396 [==============================] - 0s 467us/step - loss: 0.0296 - accuracy: 0.9949 - val_loss: 0.3533 - val_accuracy: 0.9415\n",
      "Epoch 36/40\n",
      "396/396 [==============================] - 0s 455us/step - loss: 0.0284 - accuracy: 0.9924 - val_loss: 0.3733 - val_accuracy: 0.9357\n",
      "Epoch 37/40\n",
      "396/396 [==============================] - 0s 417us/step - loss: 0.0329 - accuracy: 0.9899 - val_loss: 0.4100 - val_accuracy: 0.9298\n",
      "Epoch 38/40\n",
      "396/396 [==============================] - 0s 341us/step - loss: 0.0301 - accuracy: 0.9924 - val_loss: 0.3745 - val_accuracy: 0.9415\n",
      "Epoch 39/40\n",
      "396/396 [==============================] - 0s 346us/step - loss: 0.0194 - accuracy: 0.9975 - val_loss: 0.3837 - val_accuracy: 0.9415\n",
      "Epoch 40/40\n",
      "396/396 [==============================] - 0s 349us/step - loss: 0.0176 - accuracy: 0.9975 - val_loss: 0.4195 - val_accuracy: 0.9357\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(7)\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(30, kernel_initializer = \"uniform\",activation = \"relu\", input_dim=26))\n",
    "classifier.add(Dense(40, kernel_initializer = \"uniform\",activation = \"relu\"))\n",
    "classifier.add(Dense(30, kernel_initializer = \"uniform\",activation = \"relu\"))\n",
    "classifier.add(Dense(10, kernel_initializer = \"uniform\",activation = \"relu\"))\n",
    "classifier.add(Dense(1, kernel_initializer = \"uniform\",activation = \"sigmoid\"))\n",
    "classifier.compile(optimizer= \"adam\",loss = \"binary_crossentropy\",metrics = [\"accuracy\"])\n",
    "classifier.fit(x_train, y_train,validation_data=(x_test,y_test), batch_size = 10, epochs = 40)\n",
    "scores1 = classifier.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95       102\n",
      "           1       0.91      0.93      0.92        69\n",
      "\n",
      "    accuracy                           0.94       171\n",
      "   macro avg       0.93      0.93      0.93       171\n",
      "weighted avg       0.94      0.94      0.94       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(x_test)\n",
    "y_pred = (predictions > 0.5)\n",
    "matrix =metrics.confusion_matrix(y_test, y_pred)\n",
    "print (metrics.classification_report(y_test, y_pred, labels=[0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.23903818953323 93.43563512361466 93.33380586171457\n"
     ]
    }
   ],
   "source": [
    "precision1=metrics.precision_score(y_test,y_pred,labels=[0,1],average='macro')*100\n",
    "recall1=metrics.recall_score(y_test,y_pred,labels=[0,1],average='macro')*100\n",
    "f1_1=metrics.f1_score(y_test,y_pred,labels=[0,1],average='macro')*100\n",
    "print(precision1,recall1,f1_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 396 samples, validate on 171 samples\n",
      "Epoch 1/40\n",
      "396/396 [==============================] - 2s 4ms/step - loss: 0.6915 - accuracy: 0.5253 - val_loss: 0.6846 - val_accuracy: 0.7485\n",
      "Epoch 2/40\n",
      "396/396 [==============================] - 0s 829us/step - loss: 0.6359 - accuracy: 0.8308 - val_loss: 0.5855 - val_accuracy: 0.8363\n",
      "Epoch 3/40\n",
      "396/396 [==============================] - 0s 872us/step - loss: 0.4964 - accuracy: 0.8535 - val_loss: 0.4733 - val_accuracy: 0.8538\n",
      "Epoch 4/40\n",
      "396/396 [==============================] - 0s 824us/step - loss: 0.3797 - accuracy: 0.8485 - val_loss: 0.3741 - val_accuracy: 0.8655\n",
      "Epoch 5/40\n",
      "396/396 [==============================] - 0s 758us/step - loss: 0.3228 - accuracy: 0.8662 - val_loss: 0.3326 - val_accuracy: 0.8772\n",
      "Epoch 6/40\n",
      "396/396 [==============================] - 0s 624us/step - loss: 0.3079 - accuracy: 0.8662 - val_loss: 0.3193 - val_accuracy: 0.8830\n",
      "Epoch 7/40\n",
      "396/396 [==============================] - 0s 622us/step - loss: 0.2987 - accuracy: 0.8712 - val_loss: 0.3373 - val_accuracy: 0.8830\n",
      "Epoch 8/40\n",
      "396/396 [==============================] - 0s 649us/step - loss: 0.2916 - accuracy: 0.8813 - val_loss: 0.3192 - val_accuracy: 0.9064\n",
      "Epoch 9/40\n",
      "396/396 [==============================] - 0s 647us/step - loss: 0.2851 - accuracy: 0.8864 - val_loss: 0.3137 - val_accuracy: 0.9240\n",
      "Epoch 10/40\n",
      "396/396 [==============================] - 0s 576us/step - loss: 0.2775 - accuracy: 0.8889 - val_loss: 0.3018 - val_accuracy: 0.9240\n",
      "Epoch 11/40\n",
      "396/396 [==============================] - 0s 609us/step - loss: 0.2709 - accuracy: 0.8990 - val_loss: 0.3086 - val_accuracy: 0.9240\n",
      "Epoch 12/40\n",
      "396/396 [==============================] - 0s 599us/step - loss: 0.2629 - accuracy: 0.9066 - val_loss: 0.3046 - val_accuracy: 0.9240\n",
      "Epoch 13/40\n",
      "396/396 [==============================] - 0s 574us/step - loss: 0.2582 - accuracy: 0.9141 - val_loss: 0.3031 - val_accuracy: 0.9298\n",
      "Epoch 14/40\n",
      "396/396 [==============================] - 0s 493us/step - loss: 0.2489 - accuracy: 0.9116 - val_loss: 0.2866 - val_accuracy: 0.9415\n",
      "Epoch 15/40\n",
      "396/396 [==============================] - 0s 470us/step - loss: 0.2404 - accuracy: 0.9217 - val_loss: 0.2833 - val_accuracy: 0.9357\n",
      "Epoch 16/40\n",
      "396/396 [==============================] - 0s 531us/step - loss: 0.2326 - accuracy: 0.9242 - val_loss: 0.2692 - val_accuracy: 0.9415\n",
      "Epoch 17/40\n",
      "396/396 [==============================] - 0s 508us/step - loss: 0.2286 - accuracy: 0.9268 - val_loss: 0.2822 - val_accuracy: 0.9415\n",
      "Epoch 18/40\n",
      "396/396 [==============================] - 0s 518us/step - loss: 0.2185 - accuracy: 0.9318 - val_loss: 0.2791 - val_accuracy: 0.9474\n",
      "Epoch 19/40\n",
      "396/396 [==============================] - 0s 440us/step - loss: 0.2141 - accuracy: 0.9268 - val_loss: 0.2645 - val_accuracy: 0.9474\n",
      "Epoch 20/40\n",
      "396/396 [==============================] - 0s 488us/step - loss: 0.2071 - accuracy: 0.9343 - val_loss: 0.2532 - val_accuracy: 0.9415\n",
      "Epoch 21/40\n",
      "396/396 [==============================] - 0s 462us/step - loss: 0.2021 - accuracy: 0.9343 - val_loss: 0.2556 - val_accuracy: 0.9474\n",
      "Epoch 22/40\n",
      "396/396 [==============================] - 0s 452us/step - loss: 0.1988 - accuracy: 0.9318 - val_loss: 0.2622 - val_accuracy: 0.9474\n",
      "Epoch 23/40\n",
      "396/396 [==============================] - 0s 483us/step - loss: 0.1883 - accuracy: 0.9394 - val_loss: 0.2475 - val_accuracy: 0.9532\n",
      "Epoch 24/40\n",
      "396/396 [==============================] - 0s 417us/step - loss: 0.1799 - accuracy: 0.9419 - val_loss: 0.2452 - val_accuracy: 0.9474\n",
      "Epoch 25/40\n",
      "396/396 [==============================] - 0s 409us/step - loss: 0.1700 - accuracy: 0.9419 - val_loss: 0.2703 - val_accuracy: 0.9298\n",
      "Epoch 26/40\n",
      "396/396 [==============================] - 0s 450us/step - loss: 0.1556 - accuracy: 0.9495 - val_loss: 0.2356 - val_accuracy: 0.9591\n",
      "Epoch 27/40\n",
      "396/396 [==============================] - 0s 445us/step - loss: 0.1479 - accuracy: 0.9520 - val_loss: 0.2598 - val_accuracy: 0.9415\n",
      "Epoch 28/40\n",
      "396/396 [==============================] - 0s 483us/step - loss: 0.1373 - accuracy: 0.9545 - val_loss: 0.2470 - val_accuracy: 0.9474\n",
      "Epoch 29/40\n",
      "396/396 [==============================] - 0s 425us/step - loss: 0.1311 - accuracy: 0.9621 - val_loss: 0.2690 - val_accuracy: 0.9357\n",
      "Epoch 30/40\n",
      "396/396 [==============================] - 0s 356us/step - loss: 0.1226 - accuracy: 0.9646 - val_loss: 0.2570 - val_accuracy: 0.9474\n",
      "Epoch 31/40\n",
      "396/396 [==============================] - 0s 364us/step - loss: 0.1138 - accuracy: 0.9672 - val_loss: 0.2546 - val_accuracy: 0.9474\n",
      "Epoch 32/40\n",
      "396/396 [==============================] - 0s 389us/step - loss: 0.1096 - accuracy: 0.9697 - val_loss: 0.2711 - val_accuracy: 0.9415\n",
      "Epoch 33/40\n",
      "396/396 [==============================] - 0s 387us/step - loss: 0.1028 - accuracy: 0.9697 - val_loss: 0.2665 - val_accuracy: 0.9474\n",
      "Epoch 34/40\n",
      "396/396 [==============================] - 0s 452us/step - loss: 0.0986 - accuracy: 0.9722 - val_loss: 0.2805 - val_accuracy: 0.9474\n",
      "Epoch 35/40\n",
      "396/396 [==============================] - 0s 419us/step - loss: 0.0903 - accuracy: 0.9747 - val_loss: 0.2747 - val_accuracy: 0.9474\n",
      "Epoch 36/40\n",
      "396/396 [==============================] - 0s 371us/step - loss: 0.0877 - accuracy: 0.9747 - val_loss: 0.2740 - val_accuracy: 0.9474\n",
      "Epoch 37/40\n",
      "396/396 [==============================] - 0s 384us/step - loss: 0.0817 - accuracy: 0.9747 - val_loss: 0.2853 - val_accuracy: 0.9474\n",
      "Epoch 38/40\n",
      "396/396 [==============================] - 0s 394us/step - loss: 0.0718 - accuracy: 0.9798 - val_loss: 0.2868 - val_accuracy: 0.9474\n",
      "Epoch 39/40\n",
      "396/396 [==============================] - 0s 377us/step - loss: 0.0647 - accuracy: 0.9848 - val_loss: 0.3167 - val_accuracy: 0.9474\n",
      "Epoch 40/40\n",
      "396/396 [==============================] - 0s 412us/step - loss: 0.0579 - accuracy: 0.9848 - val_loss: 0.3302 - val_accuracy: 0.9357\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "classifier2 = Sequential()\n",
    "classifier2.add(Dense(30, kernel_initializer = \"uniform\",activation = \"relu\", input_dim=26))\n",
    "classifier2.add(Dense(40, kernel_initializer = \"uniform\",activation = \"relu\"))\n",
    "classifier2.add(Dense(30, kernel_initializer = \"uniform\",activation = \"relu\"))\n",
    "classifier2.add(Dense(10, kernel_initializer = \"uniform\",activation = \"relu\"))\n",
    "classifier2.add(Dense(1, kernel_initializer = \"uniform\",activation = \"sigmoid\"))\n",
    "classifier2.compile(optimizer= \"RMSprop\",loss = \"binary_crossentropy\",metrics = [\"accuracy\"])\n",
    "classifier2.fit(x_train, y_train,validation_data=(x_test,y_test), batch_size = 10, epochs = 40)\n",
    "scores2 = classifier2.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95       102\n",
      "           1       0.90      0.94      0.92        69\n",
      "\n",
      "    accuracy                           0.94       171\n",
      "   macro avg       0.93      0.94      0.93       171\n",
      "weighted avg       0.94      0.94      0.94       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier2.predict(x_test)\n",
    "y_pred = (predictions > 0.5)\n",
    "matrix =metrics.confusion_matrix(y_test, y_pred)\n",
    "print (metrics.classification_report(y_test, y_pred, labels=[0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.11868686868688 93.67007672634271 93.36297237218164\n"
     ]
    }
   ],
   "source": [
    "precision2=metrics.precision_score(y_test,y_pred,labels=[0,1],average='macro')*100\n",
    "recall2=metrics.recall_score(y_test,y_pred,labels=[0,1],average='macro')*100\n",
    "f1_2=metrics.f1_score(y_test,y_pred,labels=[0,1],average='macro')*100\n",
    "print(precision2,recall2,f1_2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 396 samples, validate on 171 samples\n",
      "Epoch 1/40\n",
      "396/396 [==============================] - 1s 3ms/step - loss: 0.6888 - binary_accuracy: 0.5429 - val_loss: 0.6655 - val_binary_accuracy: 0.7953\n",
      "Epoch 2/40\n",
      "396/396 [==============================] - 0s 960us/step - loss: 0.5917 - binary_accuracy: 0.8510 - val_loss: 0.4671 - val_binary_accuracy: 0.8889\n",
      "Epoch 3/40\n",
      "396/396 [==============================] - 0s 925us/step - loss: 0.4393 - binary_accuracy: 0.8485 - val_loss: 0.3550 - val_binary_accuracy: 0.8713\n",
      "Epoch 4/40\n",
      "396/396 [==============================] - 0s 983us/step - loss: 0.3429 - binary_accuracy: 0.8636 - val_loss: 0.3183 - val_binary_accuracy: 0.8655\n",
      "Epoch 5/40\n",
      "396/396 [==============================] - 0s 1ms/step - loss: 0.3107 - binary_accuracy: 0.8712 - val_loss: 0.3311 - val_binary_accuracy: 0.8889\n",
      "Epoch 6/40\n",
      "396/396 [==============================] - 0s 955us/step - loss: 0.2990 - binary_accuracy: 0.8763 - val_loss: 0.3137 - val_binary_accuracy: 0.9123\n",
      "Epoch 7/40\n",
      "396/396 [==============================] - 0s 912us/step - loss: 0.2881 - binary_accuracy: 0.8965 - val_loss: 0.3177 - val_binary_accuracy: 0.9123\n",
      "Epoch 8/40\n",
      "396/396 [==============================] - 0s 847us/step - loss: 0.2788 - binary_accuracy: 0.8914 - val_loss: 0.3073 - val_binary_accuracy: 0.9181\n",
      "Epoch 9/40\n",
      "396/396 [==============================] - 0s 809us/step - loss: 0.2713 - binary_accuracy: 0.9040 - val_loss: 0.3013 - val_binary_accuracy: 0.9181\n",
      "Epoch 10/40\n",
      "396/396 [==============================] - 0s 665us/step - loss: 0.2637 - binary_accuracy: 0.9141 - val_loss: 0.3051 - val_binary_accuracy: 0.9006\n",
      "Epoch 11/40\n",
      "396/396 [==============================] - 0s 687us/step - loss: 0.2563 - binary_accuracy: 0.9141 - val_loss: 0.3063 - val_binary_accuracy: 0.9064\n",
      "Epoch 12/40\n",
      "396/396 [==============================] - 0s 642us/step - loss: 0.2516 - binary_accuracy: 0.9192 - val_loss: 0.3017 - val_binary_accuracy: 0.9006\n",
      "Epoch 13/40\n",
      "396/396 [==============================] - 0s 634us/step - loss: 0.2444 - binary_accuracy: 0.9192 - val_loss: 0.2961 - val_binary_accuracy: 0.9181\n",
      "Epoch 14/40\n",
      "396/396 [==============================] - 0s 566us/step - loss: 0.2369 - binary_accuracy: 0.9192 - val_loss: 0.3074 - val_binary_accuracy: 0.8947\n",
      "Epoch 15/40\n",
      "396/396 [==============================] - 0s 584us/step - loss: 0.2327 - binary_accuracy: 0.9242 - val_loss: 0.2916 - val_binary_accuracy: 0.9181\n",
      "Epoch 16/40\n",
      "396/396 [==============================] - 0s 574us/step - loss: 0.2259 - binary_accuracy: 0.9217 - val_loss: 0.3034 - val_binary_accuracy: 0.9064\n",
      "Epoch 17/40\n",
      "396/396 [==============================] - 0s 561us/step - loss: 0.2226 - binary_accuracy: 0.9242 - val_loss: 0.2956 - val_binary_accuracy: 0.9064\n",
      "Epoch 18/40\n",
      "396/396 [==============================] - 0s 564us/step - loss: 0.2176 - binary_accuracy: 0.9217 - val_loss: 0.2934 - val_binary_accuracy: 0.9064\n",
      "Epoch 19/40\n",
      "396/396 [==============================] - 0s 521us/step - loss: 0.2109 - binary_accuracy: 0.9242 - val_loss: 0.3070 - val_binary_accuracy: 0.8830\n",
      "Epoch 20/40\n",
      "396/396 [==============================] - 0s 493us/step - loss: 0.2031 - binary_accuracy: 0.9293 - val_loss: 0.2881 - val_binary_accuracy: 0.9064\n",
      "Epoch 21/40\n",
      "396/396 [==============================] - 0s 556us/step - loss: 0.1962 - binary_accuracy: 0.9343 - val_loss: 0.2857 - val_binary_accuracy: 0.9064\n",
      "Epoch 22/40\n",
      "396/396 [==============================] - 0s 457us/step - loss: 0.1861 - binary_accuracy: 0.9343 - val_loss: 0.2892 - val_binary_accuracy: 0.9064\n",
      "Epoch 23/40\n",
      "396/396 [==============================] - 0s 460us/step - loss: 0.1757 - binary_accuracy: 0.9394 - val_loss: 0.2699 - val_binary_accuracy: 0.9181\n",
      "Epoch 24/40\n",
      "396/396 [==============================] - 0s 430us/step - loss: 0.1673 - binary_accuracy: 0.9470 - val_loss: 0.2729 - val_binary_accuracy: 0.9298\n",
      "Epoch 25/40\n",
      "396/396 [==============================] - 0s 427us/step - loss: 0.1628 - binary_accuracy: 0.9444 - val_loss: 0.2784 - val_binary_accuracy: 0.9240\n",
      "Epoch 26/40\n",
      "396/396 [==============================] - 0s 455us/step - loss: 0.1498 - binary_accuracy: 0.9495 - val_loss: 0.2637 - val_binary_accuracy: 0.9240\n",
      "Epoch 27/40\n",
      "396/396 [==============================] - 0s 412us/step - loss: 0.1436 - binary_accuracy: 0.9495 - val_loss: 0.2684 - val_binary_accuracy: 0.9240\n",
      "Epoch 28/40\n",
      "396/396 [==============================] - 0s 404us/step - loss: 0.1340 - binary_accuracy: 0.9545 - val_loss: 0.2726 - val_binary_accuracy: 0.9298\n",
      "Epoch 29/40\n",
      "396/396 [==============================] - 0s 432us/step - loss: 0.1257 - binary_accuracy: 0.9596 - val_loss: 0.2750 - val_binary_accuracy: 0.9298\n",
      "Epoch 30/40\n",
      "396/396 [==============================] - 0s 404us/step - loss: 0.1161 - binary_accuracy: 0.9596 - val_loss: 0.2970 - val_binary_accuracy: 0.9298\n",
      "Epoch 31/40\n",
      "396/396 [==============================] - 0s 462us/step - loss: 0.1107 - binary_accuracy: 0.9646 - val_loss: 0.2938 - val_binary_accuracy: 0.9298\n",
      "Epoch 32/40\n",
      "396/396 [==============================] - 0s 490us/step - loss: 0.0994 - binary_accuracy: 0.9672 - val_loss: 0.3010 - val_binary_accuracy: 0.9298\n",
      "Epoch 33/40\n",
      "396/396 [==============================] - 0s 427us/step - loss: 0.0900 - binary_accuracy: 0.9722 - val_loss: 0.2977 - val_binary_accuracy: 0.9298\n",
      "Epoch 34/40\n",
      "396/396 [==============================] - 0s 417us/step - loss: 0.0788 - binary_accuracy: 0.9747 - val_loss: 0.3013 - val_binary_accuracy: 0.9415\n",
      "Epoch 35/40\n",
      "396/396 [==============================] - 0s 465us/step - loss: 0.0698 - binary_accuracy: 0.9848 - val_loss: 0.3136 - val_binary_accuracy: 0.9415\n",
      "Epoch 36/40\n",
      "396/396 [==============================] - 0s 447us/step - loss: 0.0594 - binary_accuracy: 0.9848 - val_loss: 0.3334 - val_binary_accuracy: 0.9415\n",
      "Epoch 37/40\n",
      "396/396 [==============================] - 0s 432us/step - loss: 0.0554 - binary_accuracy: 0.9874 - val_loss: 0.3434 - val_binary_accuracy: 0.9415\n",
      "Epoch 38/40\n",
      "396/396 [==============================] - 0s 457us/step - loss: 0.0481 - binary_accuracy: 0.9874 - val_loss: 0.3542 - val_binary_accuracy: 0.9415\n",
      "Epoch 39/40\n",
      "396/396 [==============================] - 0s 425us/step - loss: 0.0431 - binary_accuracy: 0.9899 - val_loss: 0.3828 - val_binary_accuracy: 0.9415\n",
      "Epoch 40/40\n",
      "396/396 [==============================] - 0s 412us/step - loss: 0.0372 - binary_accuracy: 0.9924 - val_loss: 0.4385 - val_binary_accuracy: 0.9415\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(5)\n",
    "classifier3 = Sequential()\n",
    "classifier3.add(Dense(30, kernel_initializer = 'uniform',activation = \"relu\", input_dim=26))\n",
    "classifier3.add(Dense(40, kernel_initializer ='uniform', activation = \"relu\"))\n",
    "classifier3.add(Dense(30, kernel_initializer = 'uniform',activation = \"relu\"))\n",
    "classifier3.add(Dense(10, kernel_initializer ='uniform',activation = \"relu\"))\n",
    "classifier3.add(Dense(1, kernel_initializer = 'uniform',activation = \"sigmoid\"))\n",
    "classifier3.compile(optimizer= \"RMSprop\", loss = \"binary_crossentropy\",metrics = [\"binary_accuracy\"])\n",
    "classifier3.fit(x_train, y_train, validation_data=(x_test,y_test), batch_size = 10, epochs = 40)\n",
    "scores = classifier3.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95       102\n",
      "           1       0.90      0.96      0.93        69\n",
      "\n",
      "    accuracy                           0.94       171\n",
      "   macro avg       0.94      0.94      0.94       171\n",
      "weighted avg       0.94      0.94      0.94       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier3.predict(x_test)\n",
    "y_pred = (predictions > 0.5)\n",
    "matrix =metrics.confusion_matrix(y_test, y_pred)\n",
    "print (metrics.classification_report(y_test, y_pred, labels=[0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.67486720715684 94.39471440750214 93.97887323943662\n"
     ]
    }
   ],
   "source": [
    "precision3=metrics.precision_score(y_test,y_pred,labels=[0,1],average='macro')*100\n",
    "recall3=metrics.recall_score(y_test,y_pred,labels=[0,1],average='macro')*100\n",
    "f1_3=metrics.f1_score(y_test,y_pred,labels=[0,1],average='macro')*100\n",
    "print(precision3,recall3,f1_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4194752870247378, 0.9356725215911865] [0.33021651095117044, 0.9356725215911865] [0.43850217071193004, 0.9415204524993896]\n"
     ]
    }
   ],
   "source": [
    "print(scores1,scores2,scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing 3 Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_groups = 4\n",
    "classifier_1 = (scores1[1]*100,precision1,recall1,f1_1)\n",
    "classifier_2 = (scores2[1]*100,precision2,recall2,f1_2)\n",
    "classifier_3 = (scores[1]*100,precision3,recall3,f1_3)\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.30\n",
    "opacity = 0.8\n",
    "\n",
    "rects1 = plt.bar(index, classifier_1, bar_width,\n",
    "alpha=opacity,\n",
    "color='r',\n",
    "label='Classifier 1')\n",
    "\n",
    "rects2 = plt.bar(index + bar_width, classifier_2, bar_width,\n",
    "alpha=opacity,\n",
    "color='g',\n",
    "label='Classifier 2')\n",
    "\n",
    "rects3 = plt.bar(index + 2*bar_width, classifier_3, bar_width,\n",
    "alpha=opacity,\n",
    "color='b',\n",
    "label='Classifier 3')\n",
    "\n",
    "\n",
    "plt.xlabel('Systems')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Scores by Systems')\n",
    "plt.xticks(index + bar_width, ('Accuracy', 'Precision', 'Recall', 'F1-Score'))\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result: Classifier 1 is the Best Classifier in predicting Heart Disease "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
